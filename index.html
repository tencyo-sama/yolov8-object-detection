<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>YOLOv8 Object Detection</title>
  <!-- TensorFlow.js の読み込み -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <style>
    body {
      margin: 0;
      padding: 0;
      width: 100vw;
      height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
      background: #000;
    }
    .container {
      width: 100%;
      height: 85vh;
      position: relative;
      overflow: hidden;
    }
    #output {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    .button-container {
      position: fixed;
      bottom: 20px;
      width: 100%;
      display: flex;
      justify-content: center;
      gap: 20px;
      z-index: 1000;
    }
    button {
      padding: 15px 30px;
      font-size: 18px;
      border-radius: 25px;
      border: none;
      background: rgba(255, 255, 255, 0.9);
      box-shadow: 0 2px 5px rgba(0,0,0,0.2);
      cursor: pointer;
    }
    button:disabled {
      background: rgba(200, 200, 200, 0.9);
      cursor: not-allowed;
    }
    .message {
      position: fixed;
      bottom: 100px;
      left: 50%;
      transform: translateX(-50%);
      background-color: rgba(0, 0, 0, 0.7);
      color: white;
      padding: 10px 20px;
      border-radius: 5px;
      font-size: 16px;
      z-index: 1000;
      text-align: center;
      max-width: 80%;
    }
    .loading-indicator {
      border: 4px solid #f3f3f3;
      border-radius: 50%;
      border-top: 4px solid #3498db;
      width: 20px;
      height: 20px;
      animation: spin 1s linear infinite;
      display: none;
      margin: 10px auto;
    }
    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
  </style>
</head>
<body>
  <div class="container">
    <canvas id="output"></canvas>
    <video id="input" style="display: none;" playsinline autoplay muted></video>
  </div>
  <div class="message" id="message">
    <div class="loading-indicator" id="loading"></div>
    <div id="message-text"></div>
  </div>
  <div class="button-container">
    <button id="start">開始</button>
    <button id="stop" disabled>停止</button>
  </div>

  <script>
    let model;
    let isRunning = false;
    let video, canvas, messageDiv, messageText, loadingIndicator, startButton, stopButton, ctx;
    let animationFrameId;

    // 検出閾値
    const SCORE_THRESHOLD = 0.5;  // 信頼度の閾値
    const IOU_THRESHOLD = 0.45;   // IoU (Intersection over Union) の閾値
    const CLASS_NAMES = [
        'clip',
    ];
    //色の設定
    const classColors = {};
    CLASS_NAMES.forEach((className) => {
        classColors[className] = '#' + Math.floor(Math.random()*16777215).toString(16).padStart(6, '0');
    });

    // DOM要素の取得と初期化
    function initDOMElements() {
        video = document.getElementById('input');
        canvas = document.getElementById('output');
        messageDiv = document.getElementById('message');
        messageText = document.getElementById('message-text');
        loadingIndicator = document.getElementById('loading');
        startButton = document.getElementById('start');
        stopButton = document.getElementById('stop');
        ctx = canvas.getContext('2d');
    }

    //イベントリスナーの設定
    function setupEventListeners() {
        window.addEventListener('resize', resizeCanvas);
        startButton.addEventListener('click', startDetection);
        stopButton.addEventListener('click', stopDetection);
    }

   // カメラの起動
    async function startCamera() {
        const constraints = {
            video: {
                facingMode: 'environment',
                //PCでテストする場合は解像度を固定すると動作しやすい
                width: { ideal: 640 },
                height: { ideal: 640 }
            }
        };
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        await video.play();
    }

    // YOLOv8 モデルの読み込み
    async function loadModel() {
        // 重要: GitHub Pagesでは相対パスでモデルを指定
        model = await tf.loadGraphModel('./best_web_model/model.json');  // best_web_model フォルダに配置
        return model;
    }

    //検出の前処理
    function preprocess(video) {
        let tensor = tf.browser.fromPixels(video)
        return tensor.toFloat().div(tf.scalar(255))   // 0-255 -> 0-1 に正規化
    }

    // NMS (Non-Maximum Suppression)
    async function nonMaxSuppression(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      const boxes_ = tf.tensor2d(boxes);
      const scores_ = tf.tensor1d(scores);
      const nmsIndex = await tf.image.nonMaxSuppressionAsync(
        boxes_,
        scores_,
        maxOutputSize,
        iouThreshold,
        scoreThreshold
      );

      const selectedIndices = nmsIndex.dataSync();
      nmsIndex.dispose();
      boxes_.dispose();
      scores_.dispose();
      return selectedIndices;
    }

    // 検出結果を後処理して、描画可能な形にする関数
    async function postprocess(outputs, originalWidth, originalHeight) {
        // 1. テンソルを転置 (transpose)
        const transposed = tf.transpose(outputs, [0, 2, 1]);

        // 2. テンソルの形状を変更 (reshape)
        const reshaped = tf.reshape(transposed, [8400, 5]);

        const numPredictions = reshaped.shape[0]; // 予測の数 (例: 8400)

        const boxes = [];
        const scores = [];
        const classIds = [];

        const data = await reshaped.data(); // データを取得

        // 各予測について
        for (let i = 0; i < numPredictions; i++) {
            const offset = i * 5; // 各予測の開始位置

            // データの抽出
            const confidence = data[offset];   // 信頼度
            let x1 = data[offset + 1];     // バウンディングボックスの左上隅 x 座標
            let y1 = data[offset + 2];     // バウンディングボックスの左上隅 y 座標
            let x2 = data[offset + 3];  // バウンディングボックスの右下隅 x 座標
            let y2 = data[offset + 4];  // バウンディングボックスの右下隅 y 座標

            // 信頼度が低い場合はスキップ
            if (confidence < SCORE_THRESHOLD) continue;

            boxes.push([x1, y1, x2, y2]); // xyxy 形式で保存
            scores.push(confidence);
            classIds.push(0); // クラスが1つしかないため、常に 0
        }

        // NMS を適用 (Non-Maximum Suppression)
        const nmsIndices = await nonMaxSuppression(
            boxes,
            scores,
            10,
            IOU_THRESHOLD,
            SCORE_THRESHOLD
        );

        const predictions = [];
        // NMS で選択された予測のみを処理
        nmsIndices.forEach(index => {
            const box = boxes[index];
            const classId = classIds[index];
            const score = scores[index];
            const x1 = box[0];
            const y1 = box[1];
            const x2 = box[2];
            const y2 = box[3];
            const width = (x2 - x1);
            const height = (y2 - y1);

            predictions.push({
                bbox: {
                    x: x1,
                    y: y1,
                    width: width,
                    height: height
                },
                class: CLASS_NAMES[classId],
                score: score
            });
        });

        return predictions;
    }

    // 検出処理の開始
    async function startDetection() {
      try {
        updateMessage("モデルを読み込み中...");
        showLoading(true);
        startButton.disabled = true;

        if(!model){
          model = await loadModel();
        }

        updateMessage("カメラを起動中...");
        await startCamera();

        //カメラの解像度に合わせてCanvasのサイズを設定
        resizeCanvas();

        isRunning = true;
        stopButton.disabled = false;
        updateMessage("検出中", 2000);
        showLoading(false);
        detectFrame();

      } catch (error) {
          handleDetectionError(error);
      }
    }

    //検出処理の停止
    async function stopDetection() {
      isRunning = false;
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }

      if (video.srcObject) {
        video.srcObject.getTracks().forEach(track => track.stop());
        video.srcObject = null;
      }

      ctx.clearRect(0, 0, canvas.width, canvas.height);  //ビデオ停止時にキャンバスを消去する
      startButton.disabled = false;
      stopButton.disabled = true;
      updateMessage('停止しました');
    }
    // フレームごとの検出処理
    async function detectFrame() {
        if (!isRunning) return;

        const tensor = preprocess(video);
        try {
            const outputs = await model.execute(tensor);

            // outputs の構造を確認 (コンソールに出力)
            console.log("outputs:", outputs);
        
            const postprocessedPredictions = await postprocess(
                outputs, // outputs[0] または適切なキー
                video.videoWidth,
                video.videoHeight
            );

            tf.dispose(tensor);
            outputs.dispose();

            drawPredictions(postprocessedPredictions);
        } catch (error) {
            // 変更: model.execute() からのエラーを直接出力
            console.error("Error in model.execute():", error);
            updateMessage("推論中にエラーが発生しました");
            stopDetection();
        }
        animationFrameId = requestAnimationFrame(detectFrame);
    }

    // 検出結果の描画
    function drawPredictions(predictions) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);  //描画前に毎回消去を行う
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        predictions.forEach(prediction => {
            const { x, y, width, height } = prediction.bbox;
            const className = prediction.class;
            const color = classColors[className] || '#FFFFFF'; // クラスに対応する色を取得

            // Draw bounding box
            ctx.strokeStyle = color;
            ctx.lineWidth = 4;
            ctx.strokeRect(x, y, width, height);

            // Draw label
            ctx.fillStyle = color;
            ctx.font = '16px Arial';
            ctx.fillText(`${className} ${Math.round(prediction.score * 100)}%`, x, y - 5);
        });
    }

    // エラー処理
    function handleDetectionError(error) {
        console.error('Error:', error);
        let errorMessage = 'エラーが発生しました';
        if (error.name === 'NotAllowedError') {
            errorMessage = 'カメラへのアクセスが許可されていません';
        } else if (error.name === 'NotFoundError') {
            errorMessage = 'カメラが見つかりません';
        } else if (error.name === 'NotReadableError') { //追加：カメラが他のアプリで使用されている
            errorMessage = "カメラが他のアプリケーションによって使用されているため、アクセスできません。"
        }
        updateMessage(errorMessage);
        stopDetection(); // エラーが発生した場合、検出を停止
    }

    // キャンバスのリサイズ
    function resizeCanvas() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
    }

    // ローディング表示の切り替え
    function showLoading(show) {
        loadingIndicator.style.display = show ? 'block' : 'none';
    }

    // メッセージの更新
    function updateMessage(text, timeout = 0) {
        messageText.textContent = text;
        if (timeout > 0) {
            setTimeout(() => {
                messageText.textContent = '';
            }, timeout);
        }
    }

    // グローバルエラーハンドラ
    window.onerror = function (msg, url, lineNo, columnNo, error) {
        console.error('Global error:', msg, url, lineNo, columnNo, error);
        updateMessage('エラーが発生しました: ' + msg);
        showLoading(false);
        startButton.disabled = false; // エラーが発生しても、開始ボタンは再度有効にする
        stopButton.disabled = true;  // 停止ボタンは無効のままにする
        return false;
    };

    // ページのロード完了時に実行
    window.addEventListener('load', async () => {
      initDOMElements();        //DOM要素の取得
      setupEventListeners();     //イベントリスナーの設定
      updateMessage('準備完了');    //準備完了メッセージを表示
    });
  </script>
</body>
</html>